# **EthosGPT: Charting the Human Values Landscape on a Global Scale**

![EthosGPT](EthosGPT.webp)

## **Project Overview**

In a world increasingly shaped by Large Language Models (LLMs), the need for these systems to align with diverse human values has never been greater. **EthosGPT** is an open-source framework designed to map and evaluate LLMs‚Äô positioning across a multidimensional spectrum of human values, fostering cultural inclusivity and ethical adaptability.

---

## **Key Features**

- **Multidimensional Value Mapping**  
  Visualize LLM performance within a global human values framework.

- **Prompt-Based Evaluation**  
  Assess how well LLMs navigate diverse cultural contexts and ethical scenarios.

- **Comprehensive Case Studies**  
  Explore strengths and limitations through real-world examples.

- **Interactive Tools**  
  Engage with open-source data and visualization modules.

---

## **Why EthosGPT?**

### üåç **Preserving Cultural Diversity**
LLMs often risk homogenizing values, reflecting dominant cultural biases as observed in research (Tao et al., 2024; Li et al., 2024). EthosGPT emphasizes the need to preserve cultural diversity, akin to the role biodiversity plays in ecological resilience.

### ‚öñÔ∏è **Ethical AI Alignment**
EthosGPT provides critical insights for developing AI systems that are technically robust yet socially and ethically aligned (Kharchenko et al., 2024).

### üîç **Research-Driven Framework**
EthosGPT builds on foundational studies such as CVALUES and CultureLLM to ensure culturally sensitive AI (Xu et al., 2023; Li et al., 2024).

---

## **Core Components**

### üó∫Ô∏è **Multidimensional Mapping**
Leverage advanced visualizations to explore LLM alignment across diverse cultural and ethical dimensions.


### üîç **Prompt-Based Evaluation**

Analyze LLM responses using a structured prompt-based methodology, ensuring robust evaluation across scenarios.

### üìä **Interactive Data Tools**

Empower users with tools that break disciplinary boundaries, fostering cross-domain research and insights.

<div align="center">
  <table>
    <tr>
      <td align="center">
        <img src="demo2.png" alt="Demo 1" width="400">
        <br>
        <strong>Dash Interactive App Demo 1</strong>
      </td>
      <td align="center">
        <img src="demo1.png" alt="Demo 2.1" width="400">
        <br>
        <strong>Dash Interactive App Demo 2.1</strong>
      </td>
    </tr>
    <tr>
      <td align="center">
        <img src="demo4.png" alt="Demo 2.2" width="400">
        <br>
        <strong>Dash Interactive App Demo 2.2</strong>
      </td>
      <td align="center">
        <img src="demo3.png" alt="Demo 3" width="400">
        <br>
        <strong>Dash Interactive App Demo 3</strong>
      </td>
    </tr>
  </table>
</div>

---
### üìä **Interactive Data Tools**

<div align="center">
  <table>
    <thead>
      <tr>
        <th>Visualization</th>
        <th>Description</th>
        <th>How These Tools Help You Learn</th>
        <th>Webpage</th>
        <th>Source Code</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><strong>Cultural Values Comparison: Survey vs ChatGPT</strong></td>
        <td>Compare cultural value indices derived from human survey data with ChatGPT-generated responses, highlighting similarities and discrepancies across cultural dimensions.</td>
        <td>
          - Examine how ChatGPT aligns with human-surveyed cultural dimensions like individualism and power distance.  
          - Spot biases or deviations in AI outputs versus human-derived indices.
        </td>
        <td><a href="https://cultural-indices-dashboard.onrender.com/" target="_blank">Open App</a></td>
        <td><a href="https://github.com/sunshineluyao/cultural-indices-dashboard" target="_blank">GitHub Repo</a></td>
      </tr>
      <tr>
        <td><strong>Mean Square Error (MSE) Analysis by Cultural Region</strong></td>
        <td>Analyze the accuracy of ChatGPT's cultural values predictions across regions by comparing Mean Square Error (MSE) metrics, providing insight into areas for improvement.</td>
        <td>
          - Assess the accuracy of ChatGPT‚Äôs responses for different regions through MSE metrics.  
          - Highlight regions where ChatGPT‚Äôs cultural representations need improvement.
        </td>
        <td><a href="https://culture-indices-mse.onrender.com/" target="_blank">Open App</a></td>
        <td><a href="https://github.com/sunshineluyao/culture-indices-mse" target="_blank">GitHub Repo</a></td>
      </tr>
      <tr>
        <td><strong>Cultural Values Map</strong></td>
        <td>Visualize cultural value indices on an interactive map, enabling global comparisons between survey data and ChatGPT outputs.</td>
        <td>
          - Gain a visual understanding of global cultural indices through a map.  
          - Compare and contrast ChatGPT‚Äôs outputs with survey data across regions and nations.
        </td>
        <td><a href="https://culture-indices-map.onrender.com/" target="_blank">Open App</a></td>
        <td><a href="https://github.com/sunshineluyao/culture-indices-map" target="_blank">GitHub Repo</a></td>
      </tr>
    </tbody>
  </table>
</div>
---

## **How It Works**

1. **Prompt Input**  
   EthosGPT uses carefully crafted prompts to probe LLM responses across cultural and ethical contexts.

2. **Response Evaluation**  
   Evaluate the LLM‚Äôs alignment using predefined criteria such as Hofstede‚Äôs cultural dimensions (Kharchenko et al., 2024).

3. **Visualize Results**  
   Generate intuitive visualizations that map LLM performance, highlighting strengths and potential biases.

---

## References

- Xu, G., Liu, J., Yan, M., et al. (2023). CVALUES: Measuring the Values of Chinese Large Language Models from Safety to Responsibility. [arXiv:2307.09705v1](https://arxiv.org/abs/2307.09705).
- Li, C., Chen, M., Wang, J., et al. (2024). CultureLLM: Incorporating Cultural Differences into Large Language Models. [arXiv:2402.10946v2](https://arxiv.org/abs/2402.10946).
- Kharchenko, J., Roosta, T., Chadha, A., & Shah, C. (2024). How Well Do LLMs Represent Values Across Cultures? Empirical Analysis of LLM Responses Based on Hofstede Cultural Dimensions. [arXiv:2406.14805v1](https://arxiv.org/abs/2406.14805).
- Tao, Y., Viberg, O., Baker, R. S., & Kizilcec, R. F. (2024). Cultural Bias and Cultural Alignment of Large Language Models. *PNAS Nexus*, 3, pgae346. [DOI:10.1093/pnasnexus/pgae346](https://doi.org/10.1093/pnasnexus/pgae346).
- Durante, Z., Huang, Q., Wake, N., et al. (2024). Agent AI: Surveying the Horizons of Multimodal Interaction. [arXiv:2401.03568v2](https://arxiv.org/abs/2401.03568).
- Frisch, I., Giulianelli, M. (2024). LLM Agents in Interaction: Measuring Personality Consi
